import streamlit as st
from streamlit_webrtc import webrtc_streamer, VideoProcessorBase, RTCConfiguration
import cv2
import mediapipe as mp
import numpy as np
import joblib
import av
from collections import deque
import math
import os

# =========================================================
# 1. ì„¤ì • ë° ìƒìˆ˜ ì •ì˜
# =========================================================
MODEL_PATH = 'seq_sign_model_final.joblib' 
SEQ_LENGTH = 40
MAP_WIDTH = 500
CAM_WIDTH = 500
HEIGHT = 700
TOTAL_WIDTH = MAP_WIDTH + CAM_WIDTH
BG_COLOR = (40, 40, 40)
ROOM_COLOR = (200, 200, 200)
ROBOT_COLOR = (50, 50, 255)
TEXT_COLOR = (0, 0, 0)

ROOMS = {
    'toilet':   (250, 100, 200, 80),
    'room2':    (250, 220, 200, 80),
    'room1':    (250, 340, 200, 80),
    'elevator': (250, 460, 200, 80),
    'home':     (250, 600, 80, 50)
}

# =========================================================
# 2. ëª¨ë¸ ë¡œë“œ (ìºì‹±)
# =========================================================
@st.cache_resource
def load_model():
    if not os.path.exists(MODEL_PATH):
        return None
    try:
        return joblib.load(MODEL_PATH)
    except Exception as e:
        st.error(f"ëª¨ë¸ ë¡œë“œ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        return None

# =========================================================
# 3. ë°ì´í„° ì¶”ì¶œ í•¨ìˆ˜
# =========================================================
def extract_xyz(hand_lms):
    if hand_lms is None: return [0.0] * 63
    out = []
    for lm in hand_lms.landmark:
        out.extend([lm.x, lm.y, lm.z])
    return out

# =========================================================
# 4. ì˜ìƒ ì²˜ë¦¬ê¸° í´ë˜ìŠ¤
# =========================================================
class SignLanguageProcessor(VideoProcessorBase):
    def __init__(self):
        self.model = load_model()
        self.mp_hands = mp.solutions.hands
        self.mp_drawing = mp.solutions.drawing_utils
        self.hands = self.mp_hands.Hands(
            max_num_hands=2, 
            min_detection_confidence=0.5, 
            min_tracking_confidence=0.5
        )
        self.seq_buffer = deque(maxlen=SEQ_LENGTH)
        self.rx, self.ry = ROOMS['home'][0], ROOMS['home'][1]
        self.tx, self.ty = self.rx, self.ry
        self.speed = 4
        self.status = "Ready"
        self.last_action = "None"
        self.confidence = 0.0

    def update_robot(self):
        dx = self.tx - self.rx
        dy = self.ty - self.ry
        dist = math.hypot(dx, dy)
        if dist > self.speed:
            self.rx += (dx / dist) * self.speed
            self.ry += (dy / dist) * self.speed
        else:
            self.rx = self.tx
            self.ry = self.ty
            if "Moving" in self.status or "Returning" in self.status:
                self.status = "Arrived"

    def draw_map(self, canvas):
        cv2.rectangle(canvas, (0, 0), (MAP_WIDTH, HEIGHT), BG_COLOR, -1)
        cv2.line(canvas, (250, 100), (250, 600), (100, 100, 100), 10)
        for name, (cx, cy, w, h) in ROOMS.items():
            color = ROOM_COLOR
            if name == 'home': color = (255, 100, 100) 
            elif name == 'elevator': color = (100, 255, 255) 
            elif name == 'toilet': color = (255, 255, 100) 
            tl = (cx - w//2, cy - h//2)
            br = (cx + w//2, cy + h//2)
            cv2.rectangle(canvas, tl, br, color, -1)
            cv2.rectangle(canvas, tl, br, (255, 255, 255), 2)
            cv2.putText(canvas, name.upper(), (cx - 40, cy + 5), 
                        cv2.FONT_HERSHEY_SIMPLEX, 0.6, TEXT_COLOR, 2)
        cv2.circle(canvas, (int(self.rx), int(self.ry)), 15, ROBOT_COLOR, -1)
        cv2.circle(canvas, (int(self.rx), int(self.ry)), 15, (255,255,255), 2)

    def recv(self, frame):
        img = frame.to_ndarray(format="bgr24")
        canvas = np.zeros((HEIGHT, TOTAL_WIDTH, 3), dtype=np.uint8)
        image_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)
        result = self.hands.process(image_rgb)
        left_hand, right_hand = None, None
        if result.multi_hand_landmarks:
            for hand_lms, handedness in zip(result.multi_hand_landmarks, result.multi_handedness):
                self.mp_drawing.draw_landmarks(img, hand_lms, self.mp_hands.HAND_CONNECTIONS)
                label = handedness.classification[0].label
                if label == 'Left': left_hand = hand_lms
                else: right_hand = hand_lms
        
        self.seq_buffer.append(extract_xyz(left_hand) + extract_xyz(right_hand))

        if self.model and len(self.seq_buffer) == SEQ_LENGTH:
            input_data = np.array(self.seq_buffer).flatten().reshape(1, -1)
            probs = self.model.predict_proba(input_data)[0]
            idx = np.argmax(probs)
            self.confidence = probs[idx]
            action = self.model.classes_[idx]

            if self.confidence > 0.8:
                self.last_action = action
                if action == 'thankyou':
                    self.tx, self.ty = ROOMS['home'][0], ROOMS['home'][1]
                    self.status = "Returning Home..."
                elif action in ROOMS:
                    self.tx, self.ty = ROOMS[action][0], ROOMS[action][1]
                    self.status = f"Moving to {action.upper()}"

        self.update_robot()
        self.draw_map(canvas)
        img_resized = cv2.resize(img, (CAM_WIDTH, int(CAM_WIDTH * 0.75)))
        y_offset = (HEIGHT - img_resized.shape[0]) // 2
        canvas[y_offset:y_offset+img_resized.shape[0], MAP_WIDTH:TOTAL_WIDTH] = img_resized
        
        info_x = MAP_WIDTH + 20
        cv2.putText(canvas, f"STATUS: {self.status}", (info_x, 50), 
                    cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0, 255, 0), 2)
        cv2.putText(canvas, f"ACTION: {self.last_action.upper()}", (info_x, 90), 
                    cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0, 255, 255), 2)
        cv2.putText(canvas, f"CONF: {self.confidence*100:.1f}%", (info_x, 130), 
                    cv2.FONT_HERSHEY_SIMPLEX, 0.8, (255, 255, 255), 2)
        return av.VideoFrame.from_ndarray(canvas, format="bgr24")

# =========================================================
# 5. í˜ì´ì§€ í•¨ìˆ˜ ì •ì˜
# =========================================================

def show_intro_page():
    st.title("ğŸ“˜ ìˆ˜í™” ë™ì‘ ê°€ì´ë“œ")
    st.markdown("""
    ì•„ë˜ì˜ ìˆ˜í™” ë™ì‘ì„ ì›¹ìº ì— ë³´ì—¬ì£¼ë©´ ë¡œë´‡ì´ ì¸ì‹í•˜ì—¬ í•´ë‹¹ ì¥ì†Œë¡œ ì´ë™í•˜ê±°ë‚˜ ë³µê·€í•©ë‹ˆë‹¤.  
    **[ë™ì‘ ì˜ìƒ ë³´ê¸°]** ë²„íŠ¼ì„ ëˆ„ë¥´ë©´ êµ­ë¦½êµ­ì–´ì› í•œêµ­ìˆ˜ì–´ì‚¬ì „ì˜ ì •í™•í•œ ì˜ìƒìœ¼ë¡œ ì—°ê²°ë©ë‹ˆë‹¤.
    """)
    st.divider()

    # 3ê°œì˜ ì»¬ëŸ¼ìœ¼ë¡œ ë‚˜ëˆ„ì–´ ë°°ì¹˜
    col1, col2, col3 = st.columns(3)

    # 1. í™”ì¥ì‹¤ (Toilet)
    with col1:
        st.subheader("ğŸš½ í™”ì¥ì‹¤ (Toilet)")
        st.markdown("**ëª…ë ¹: `Move to Toilet`**")
        st.info("ë¡œë´‡ì´ **í™”ì¥ì‹¤** êµ¬ì—­ìœ¼ë¡œ ì´ë™í•©ë‹ˆë‹¤.")
        st.write("ì˜¤ë¥¸ ì£¼ë¨¹ì˜ 1Â·5ì§€ë¥¼ í´ì„œ ì½”ë¥¼ ì¥ì—ˆë‹¤ê°€ ë–¼ë©° ì£¼ë¨¹ì„ ì¥¡ë‹ˆë‹¤.")
        st.link_button("â–¶ï¸ ë™ì‘ ì˜ìƒ ë³´ê¸°", "https://sldict.korean.go.kr/front/sign/signContentsView.do?origin_no=971&top_category=CTE&category=&searchKeyword=%ED%99%94%EC%9E%A5%EC%8B%A4&searchCondition=&search_gubun=&museum_type=00&current_pos_index=0")

    # 2. ê°•ì˜ì‹¤ (Lecture Room) -> Room1/2 ë§¤í•‘
    with col2:
        st.subheader("ğŸ« ê°•ì˜ì‹¤ (Classroom)")
        st.markdown("**ëª…ë ¹: `Move to Room`**")
        st.info("ë¡œë´‡ì´ **Room 1** ë˜ëŠ” **Room 2**ë¡œ ì´ë™í•©ë‹ˆë‹¤.")
        st.write("ë‘ ì£¼ë¨¹ì„ ì¥ê³  ì†ëª©ì„ ì—‡ê±¸ì–´ ë‘ ë²ˆ ë‘ë“œë¦½ë‹ˆë‹¤.") # ìˆ˜ì–´ì‚¬ì „ ì„¤ëª… ìš”ì•½
        st.link_button("â–¶ï¸ ë™ì‘ ì˜ìƒ ë³´ê¸°", "https://sldict.korean.go.kr/front/sign/signContentsView.do?origin_no=6305&top_category=CTE&category=&searchKeyword=%EA%B5%90%EC%8B%A4&searchCondition=&search_gubun=&museum_type=00&current_pos_index=0")

    # 3. ê³ ë§ˆì›Œ (Thank You) -> Home ë³µê·€
    with col3:
        st.subheader("ğŸ™‡ ê³ ë§ˆì›Œ (Thanks)")
        st.markdown("**ëª…ë ¹: `Return Home`**")
        st.success("ë¡œë´‡ì´ **ì‹œì‘ ì§€ì (Home)**ìœ¼ë¡œ ë³µê·€í•©ë‹ˆë‹¤.")
        st.write("ì†ì„ í´ì„œ ì†ë‚ ë¡œ ë‹¤ë¥¸ ì†ì˜ ì†ë“±ì„ ë‘ ë²ˆ ë‘ë“œë¦½ë‹ˆë‹¤.")
        st.link_button("â–¶ï¸ ë™ì‘ ì˜ìƒ ë³´ê¸°", "https://sldict.korean.go.kr/front/sign/signContentsView.do?origin_no=2372&top_category=CTE&category=&searchKeyword=%EA%B0%90%EC%82%AC&searchCondition=&search_gubun=&museum_type=00&current_pos_index=0")

    st.divider()
    st.warning("âš ï¸ **Tip**: ì›¹ìº  ì •ë©´ì—ì„œ ì† ë™ì‘ì„ í¬ê³  ì •í™•í•˜ê²Œ í•´ì£¼ì„¸ìš”.")

def show_simulation_page():
    st.header("ğŸ¤– Robot Simulation")
    
    # 1. ëª¨ë¸ ë¡œë”© ëŒ€ê¸° í‘œì‹œ (ì‚¬ìš©ìê°€ ë©ˆì¶˜ ì¤„ ì•Œì§€ ì•Šê²Œ í•¨)
    with st.spinner("ğŸ§  AI ëª¨ë¸ì„ ë¶ˆëŸ¬ì˜¤ëŠ” ì¤‘ì…ë‹ˆë‹¤... (ìµœì´ˆ 1íšŒëŠ” ì‹œê°„ì´ ê±¸ë¦´ ìˆ˜ ìˆìŠµë‹ˆë‹¤)"):
        if not os.path.exists(MODEL_PATH):
            st.error(f"âš ï¸ `{MODEL_PATH}` íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ê²½ë¡œë¥¼ í™•ì¸í•´ì£¼ì„¸ìš”.")
            return
        # ëª¨ë¸ì„ ë¯¸ë¦¬ ë¡œë“œí•˜ì—¬ ìºì‹± í™•ì‹¤íˆ í•˜ê¸°
        load_model()

    st.markdown("""
    ì™¼ìª½ì€ **ë¡œë´‡ ì‹œë®¬ë ˆì´ì…˜**, ì˜¤ë¥¸ìª½ì€ **ì›¹ìº **ì…ë‹ˆë‹¤.  
    ì¹´ë©”ë¼ê°€ ì¼œì§ˆ ë•Œê¹Œì§€ **5~10ì´ˆ** ì •ë„ ê±¸ë¦´ ìˆ˜ ìˆìŠµë‹ˆë‹¤. 'START' ë²„íŠ¼ì„ ëˆŒëŸ¬ì£¼ì„¸ìš”.
    """)

    # 2. ì—°ê²° ì†ë„ ê°œì„ ì„ ìœ„í•œ STUN ì„œë²„ ì¶”ê°€
    # êµ¬ê¸€ì˜ ê¸°ë³¸ ì„œë²„ ì™¸ì— ë°±ì—… ì„œë²„ë“¤ì„ ì¶”ê°€í•˜ì—¬ ì—°ê²° ì„±ê³µë¥ ì„ ë†’ì…ë‹ˆë‹¤.
    rtc_config = RTCConfiguration({
        "iceServers": [
            {"urls": ["stun:stun.l.google.com:19302"]},
            {"urls": ["stun:stun1.l.google.com:19302"]},
            {"urls": ["stun:stun2.l.google.com:19302"]},
            {"urls": ["stun:stun3.l.google.com:19302"]},
        ]
    })

    # 3. WebRTC ìŠ¤íŠ¸ë¦¬ë¨¸ ì‹¤í–‰
    ctx = webrtc_streamer(
        key="sign-language",
        video_processor_factory=SignLanguageProcessor,
        rtc_configuration=rtc_config,
        media_stream_constraints={
            "video": {
                "width": {"ideal": 480},  # í•´ìƒë„ë¥¼ ë‚®ì¶°ì„œ ì „ì†¡ ì†ë„ í–¥ìƒ
                "height": {"ideal": 360}, 
                "frameRate": {"ideal": 15} # í”„ë ˆì„ ìˆ˜ë¥¼ ë‚®ì¶°ì„œ ë²„ë²…ì„ ë°©ì§€
            }, 
            "audio": False
        },
        async_processing=True,
    )
# =========================================================
# 6. Main App Structure
# =========================================================
def main():
    st.set_page_config(page_title="AI Robot Navigation", layout="wide")
    
    # ì‚¬ì´ë“œë°”ì—ì„œ í˜ì´ì§€ ì„ íƒ
    st.sidebar.title("ë©”ë‰´")
    page = st.sidebar.radio("ì´ë™í•  í˜ì´ì§€ë¥¼ ì„ íƒí•˜ì„¸ìš”:", ["ìˆ˜í™” ê°€ì´ë“œ", "ë¡œë´‡ ì‹œë®¬ë ˆì´ì…˜"])

    if page == "ìˆ˜í™” ê°€ì´ë“œ":
        show_intro_page()
    elif page == "ë¡œë´‡ ì‹œë®¬ë ˆì´ì…˜":
        show_simulation_page()

if __name__ == "__main__":
    main()

